{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1 - Introduction\n",
    "## Contexte\n",
    "\n",
    "Dans le cadre de mon arrivée en CDI à [SQLI](https://www.sqli.com/int-en) et en vue de la préparation du contrat CIFRE, je me suis posé comme défie de résoudre une compétition sur Kaggle, j'ai souhaité utiliser mes connaissances acquises précédemment pour la résolution de ce dataset [Mushrooms images classification 215](https://www.kaggle.com/datasets/daniilonishchenko/mushrooms-images-classification-215/data).\n",
    "\n",
    "## Présenation du dataset\n",
    "> **Un dataset (jeu de données)** : Ensemble de données (ici des images) organisée en classe.\n",
    "\n",
    "Le jeu de données est composé de 3 122 images dont les images sont 512 pixels de largeur et de longueur. Ces images sont réparties en 215 classes de champignons différents.\n",
    "\n",
    "## Objectifs\n",
    "\n",
    "L'objectif principal est de confronter plusieurs algorithmes de classification d'image dans plusieurs conditions différentes.\n",
    "\n",
    "Le second est de pouvoirs, faire un état de l'art de mes connaissances dans le domaine de la classification d'image."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 - Préparation des données (data wrangling)\n",
    "## Définitions\n",
    "\n",
    "> **Préparation des données (ou [data wrangling](https://datascientest.com/data-wrangling-tout-savoir))** :\n",
    "> *Qu'est-ce donc ?* C'est un processus précédant toutes tâches d'exploitation des données telles que des processus d'analyse ou machine learning.\n",
    "> *Comment ?* Il n'existe pas de méthodes types déjà écrites, la méthode est à concevoir selon les données.\n",
    "> *Pourquoi ?* Le processus permet de transformer des données récupérées brutes, souvent non structurées, en données structurées et exploitables facilement.\n",
    "\n",
    "> **Augmentation des données (ou [data augmentation](https://datascientest.com/data-augmentation-tout-savoir))** :\n",
    "> *Qu'est-ce donc ?* C’est un processus qui créée de la donnée en se fondant sur des données déjà existantes.\n",
    "> *Comment ?* Les nouvelles données sont créées en apportant des modifications sur certaines caractéristiques. (ex : pour les images, on joue alors sur l’échelle, l’orientation, les couleurs, la luminosité, etc).\n",
    "> *Pourquoi ?* Dans certains cas, pour qu’un algorithme arrive à généraliser le modèle, dans le cas où les données en entrée ne sont pas variées et/ou peu nombreuse.\n",
    "\n",
    "> **Nuancier de gris (greyscale) :** Une palette de couleur composée uniquement de niveaux de gris. Sur une image, cela signifie que chaque pixel correspond à une quantité de lumière, blanc étant l'intensité la plus forte et noir la plus faible.\n",
    "\n",
    "> **Nuancier de couleur (RGB (Red, Green, Blue)) :** Une palette de couleur composée de trois canaux : rouge, vert et bleu. Chaque canal défini l'intensité de la couleur. Ces trois canaux sont ensuite *superposés* pour former une image colorée.\n",
    "\n",
    "> **Train set :** est un sous-ensemble d'un dataset, utilisé en entrée d'un algorithme pour ajuster les paramètres d'un modèle.\n",
    "\n",
    "> **Validation set :** est le sous-ensemble d'un dataset, utilisé pour valider l'ajustement d'un modèle à la fin d'une époque (définition dans la partie 4).\n",
    "\n",
    "> **Test set :** est le sous-ensemble d'un dataset, utilisé pour valider l'ajustement final d'un modèle à la fin de la phase d'entraînement.\n",
    "\n",
    "Dans le processus défini, nous devons générer quatre datasets : avec et sans data augmentation puis en nuancier de gris et de couleurs."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "\n",
    "import numpy as np\n",
    "from skimage import filters\n",
    "from skimage import util\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_root = f\"./dataset\"\n",
    "\n",
    "path_datas_zip = f\"{path_root}/archive.zip\"\n",
    "path_data_root = f\"{path_root}/data/\"\n",
    "path_data_directory = f\"{path_data_root}/data/data/\"\n",
    "\n",
    "path_datasets_corrected = f\"{path_root}/data-corrected/\"\n",
    "\n",
    "path_datasets = f\"{path_root}/Fruits-100/\"\n",
    "\n",
    "path_datasets_augmented = f\"{path_root}/data-augmented-corrected/\"\n",
    "path_datasets_augmented_trainTest = f\"{path_root}/dataset-augmented/\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def removeAndCreateFolder(path):\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.mkdir(path, 0o777)\n",
    "\n",
    "def trainAndValidateSet(path, ratio):\n",
    "    return (\n",
    "        tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            path,\n",
    "            validation_split = ratio,\n",
    "            subset = \"training\",\n",
    "            seed = 42,\n",
    "            labels = \"inferred\"\n",
    "        ),\n",
    "        tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            path,\n",
    "            validation_split = ratio,\n",
    "            subset = \"validation\",\n",
    "            seed = 42,\n",
    "            labels = \"inferred\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "def CopyDataset(path_src, path_dst):\n",
    "    removeAndCreateFolder(path_datasets)\n",
    "    removeAndCreateFolder(path_dst)\n",
    "    \n",
    "    removeAndCreateFolder(f\"{path_dst}/test/\")\n",
    "    removeAndCreateFolder(f\"{path_dst}/temp/\")\n",
    "    temp_set , test_set = trainAndValidateSet(path_src, 0.2)\n",
    "    for class_name in temp_set.class_names:\n",
    "        os.mkdir(f\"{path_dst}/temp/{class_name}\")\n",
    "    for file_path in temp_set.file_paths:\n",
    "        shutil.copyfile(file_path, f\"{path_dst}/temp/{file_path.replace(path_src, '')}\")\n",
    "\n",
    "\n",
    "    for class_name in test_set.class_names:\n",
    "        os.mkdir(f\"{path_dst}/test/{class_name}\")\n",
    "    for file_path in test_set.file_paths:\n",
    "        shutil.copyfile(file_path, f\"{path_dst}/test/{file_path.replace(path_src, '')}\")\n",
    "\n",
    "\n",
    "    removeAndCreateFolder(f\"{path_dst}/train/\")\n",
    "    removeAndCreateFolder(f\"{path_dst}/validation/\")\n",
    "    train_set , validation_set = trainAndValidateSet(f\"{path_dst}/temp/\", 0.25)    \n",
    "    for class_name in train_set.class_names:\n",
    "        os.mkdir(f\"{path_dst}/train/{class_name}\")\n",
    "    for file_path in train_set.file_paths:\n",
    "        shutil.copyfile(file_path, file_path.replace('/temp/', '/train/'))\n",
    "\n",
    "\n",
    "    for class_name in validation_set.class_names:\n",
    "        os.mkdir(f\"{path_dst}/validation/{class_name}\")\n",
    "    for file_path in validation_set.file_paths:\n",
    "        shutil.copyfile(file_path, file_path.replace('/temp/', '/validation/'))\n",
    "        \n",
    "    shutil.rmtree(f\"{path_dst}/temp/\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Extraction du zip"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "removeAndCreateFolder(path_data_root)\n",
    "\n",
    "pictures = pd.DataFrame(columns = [\"FileName\", \"Width\", \"Height\", \"Mode\", \"Label\"])\n",
    "\n",
    "if len(os.listdir(path_data_root)) == 0:\n",
    "    with ZipFile(path_datas_zip, 'r') as zip_file:\n",
    "        zip_file.extractall(path_data_root)\n",
    "        print(f\"The '{path_datas_zip}' folder has been extracted.\")\n",
    "\n",
    "for folder in os.listdir(path_data_directory):\n",
    "    for file in os.listdir(f\"{path_data_directory}/{folder}\"):\n",
    "        image = Image.open(f\"{path_data_directory}/{folder}/{file}\")\n",
    "\n",
    "        pictures = pd.concat([\n",
    "            pictures,\n",
    "            pd.DataFrame({\n",
    "                \"FileName\": [file],\n",
    "                \"Width\": [float(image.size[0])],\n",
    "                \"Height\": [float(image.size[1])],\n",
    "                \"Mode\": [image.mode],\n",
    "                \"Label\": [folder],\n",
    "            })\n",
    "        ])\n",
    "            \n",
    "    print(f\"The '{folder}' folder has been read.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Corection des données"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "removeAndCreateFolder(path_datasets_corrected)\n",
    "\n",
    "if len(os.listdir(path_datasets_corrected)) == 0:\n",
    "    for index, row in pictures.iterrows():\n",
    "        image = Image.open(f\"{path_data_directory}/{row['Label']}/{row['FileName']}\")\n",
    "\n",
    "        if not os.path.exists(f\"{path_datasets_corrected}/{row['Label']}\"):\n",
    "            os.mkdir(f\"{path_datasets_corrected}/{row['Label']}\", 0o777)\n",
    "        \n",
    "        image.copy().convert(\"RGB\").save(f\"{path_datasets_corrected}/{row['Label']}/{row['FileName']}\", \"PNG\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Préparation *sans* data augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not os.path.exists(path_datasets):\n",
    "    CopyDataset(path_datasets_corrected, path_datasets)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Préparation *avec* data augmentation\n",
    "\n",
    "Pour la data augmentation, j'ai décidé, à partir des images du dataset, de générer six images de plus pour chaque image.\n",
    "Le processus choisira aléatoirement des valeurs pour les quatre paramètres, selon les conditions suivantes :\n",
    "- Rotation : $[0 ; 360]$,\n",
    "- Miroire : $\\{True, False\\}$,\n",
    "- Filtre Gaussien : $[0 ; 1]$\n",
    "- Bruitage : $[0 ; 0.05]$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "removeAndCreateFolder(path_datasets_augmented)\n",
    "\n",
    "if len(os.listdir(path_datasets_augmented)) == 0:\n",
    "    for index, row in pictures.iterrows():\n",
    "        image = Image.open(f\"{path_data_directory}/{row['Label']}/{row['FileName']}\")\n",
    "\n",
    "        if not os.path.exists(f\"{path_datasets_augmented}/{row['Label']}\"):\n",
    "            os.mkdir(f\"{path_datasets_augmented}/{row['Label']}\", 0o777)\n",
    "\n",
    "        image.copy().convert(\"RGB\").save(f\"{path_datasets_augmented}/{row['Label']}/0-{row['FileName']}\", \"PNG\")\n",
    "\n",
    "        for i in range(1, 15):\n",
    "            imageTmp = image.copy()\n",
    "            imageTmp = np.array(imageTmp)\n",
    "            \n",
    "            imageTmp = filters.gaussian(imageTmp, sigma = random.uniform(0, 1))\n",
    "            imageTmp = util.random_noise(imageTmp, mode = \"speckle\", var = random.uniform(0, 0.05))\n",
    "            imageTmp = (imageTmp * 255).astype(np.uint8)\n",
    "\n",
    "            imageTmp = Image.fromarray(imageTmp)\n",
    "            imageTmp = imageTmp.rotate(random.randint(0, 360))\n",
    "\n",
    "            if random.choice([True, False]):\n",
    "                imageTmp = ImageOps.mirror(imageTmp)\n",
    "\n",
    "            imageTmp = imageTmp.convert(\"RGB\")\n",
    "            \n",
    "            imageTmp.save(f\"{path_datasets_augmented}/{row['Label']}/{i}-{row['FileName']}\", \"PNG\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not os.path.exists(path_datasets_augmented_trainTest):\n",
    "    CopyDataset(path_datasets_augmented, path_datasets_augmented_trainTest)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fonction d'importation des datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def loadDataSet(path_dataset, shape):\n",
    "    return (\n",
    "        tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            f\"{path_dataset}/train/\",\n",
    "            validation_split = 0.2,\n",
    "            subset = \"training\",\n",
    "            seed = 42,\n",
    "            labels = \"inferred\",\n",
    "            image_size = shape\n",
    "        ),\n",
    "        tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            f\"{path_dataset}/train/\",\n",
    "            validation_split = 0.2,\n",
    "            subset = \"validation\",\n",
    "            seed = 42,\n",
    "            labels = \"inferred\",\n",
    "            image_size = shape\n",
    "        ),\n",
    "        tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            f\"{path_dataset}/test/\",\n",
    "            labels = \"inferred\",\n",
    "            image_size = shape\n",
    "        )\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 - Présentation des modèles\n",
    "## Type de problème\n",
    "\n",
    "> **Apprentissage supervisé (Supervised Learning) :** les algorithmes utilisent des datasets labellisé/étiqueté qui est utilisé pour entraîner l'algorithme. L'algorithme peut ensuite faire des prédictions sur des données inédites.\n",
    "\n",
    "> **Apprentissage non supervisé (Unsupervised Learning) :** ces algorithmes sont entrainés avec uniquement les données en entrée, il n'y a donc pas de labels/étiquettes.\n",
    "\n",
    "> **Apprentissage par renforcement (Reinforcement Learning) :** ces algorithmes « forment » un système dans un environnement dynamique, qui lui fournie en retour des « bon point » et « mauvais point ». Le but pour le système est d'obtenir le maximum de bon point.\n",
    "\n",
    "![Schéma des applications du machine learning regroupé par type d'apprentissage.](./images/MachineLearning-Introduction%20-%20Type%20d'apprentissage.drawio.png \"Schéma des applications du machine learning regroupé par type d'apprentissage.\")\n",
    "\n",
    "Le type de problème que nous rencontrons est une classification d'images en 215 classes, ce type de problème est un apprentissage supervisé.\n",
    "\n",
    "Dans les problèmes de classification d'image, nous utilisons des réseaux de neurones, ce type d'algorithme font partie de la famille du deep learning, lui-même faisant partie de la famille du machine learning.\n",
    "\n",
    "![Comparaison deep learning, machine learning et intelligence artificielle](./images/MachineLearning-Introduction%20-%20Familles.drawio.png \"Comparaison deep learning, machine learning et intelligence artificielle\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model, losses, activations, applications"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Perceptron multi-couches\n",
    "### Définitions\n",
    "\n",
    "Le Perceptron est une modélisation informatique du neurone formel apparue en 1957 par Frank Rosenblatt avec les règles d'apprentissage du Perceptron. L'algorithme se décline en deux implémentations : mono-couche et multicouche.\n",
    "\n",
    "#### **Neurone formel (neurone McCulloch-Pitts)**\n",
    "\n",
    "Avant de commencer l'explication d'un neurone formel, un petit rappel du fonctionnement d'un neurone biologique s'impose. Le neurone est divisé en deux parties : le corps cellulaire et l'axone.\n",
    "- Le corps cellulaire est composé de plusieurs dendrites pour simplifier l'entrée du neurone connectée au noyau enveloppé dans une membrane cytoplasmique et qui peut être ici décrit comme un agent décideur.\n",
    "- L'axone peut être simplifié comme la sortie du neurone.\n",
    "\n",
    "<img alt=\"Schéma simplifié d&amp;amp;amp;amp;amp;#39;un neurone schoolmov\" height=\"400\" src=\"https://images.schoolmouv.fr/gssm-svt-img30p.png\" title=\"Schéma simplifié d&amp;amp;amp;amp;amp;#39;un neurone schoolmov\" width=\"650\"/>\n",
    "\n",
    "Effectué par Warren McCulloch et Walter Pitts en 1943, le neurone formel est la formalisation mathématique du neurone biologie et fonctionne de la même manière, nous avons des \"dendrites\" qui sont la somme des valeurs d'entrée (représenté par un vecteur noté $\\overrightarrow{X}$) multiplié par leurs poids respectifs. Cette somme est ensuite soumise au noyau, ce dernier va \"traiter\" la valeur avec une fonction mathématique que l'on appelle fonction d'activation. À la sortie de la fonction, nous retrouvons la valeur calculé fait par le neurone que nous pouvons identifier comme l'axone sur le neurone biologique.\n",
    "\n",
    "![Formalisation mathématique du neurone biologique](./images/MachineLearning-MLP%20-%20Neurone%20Formel.drawio.png \"Formalisation mathématique du neurone biologique\")\n",
    "\n",
    "> Légende :\n",
    "> - $x_0$ le biais,\n",
    "> - $\\overrightarrow{X}$ le vecteur d'entrée,\n",
    "> - $f$ fonction d'activation souvent sigmoïd,\n",
    "> - $\\theta$ le seuil de la fonction d'activation, pas obligatoire dépend de la fonction choisie,\n",
    "> - $Y$ la sortie du neurone.\n",
    "\n",
    "#### **Vecteur d'entrée** $\\overrightarrow{X}$\n",
    "\n",
    "C'est le paramètre envoyé en entrée d'un réseau de neurone, les paramètres sont noté mathématiquement : $\\overrightarrow{X} \\begin{pmatrix}\n",
    "x_1 \\\\\n",
    "x_{...} \\\\\n",
    "x_d \\\\\n",
    "\\end{pmatrix}$.\n",
    "\n",
    "#### **Fonction d'activation**\n",
    "\n",
    "Une fonction reprend le principe du potentiel d'activation d'un neurone biologique, c'est-à-dire une fonction qui définit le seuil pour la sortie du neurone.\n",
    "\n",
    " **Exemple - la fonction sigmoïde (fonction logistique)** : $ f(x) = \\frac{1}{1 + \\mathrm{e}^{-x}} $ où $ f(x) \\in ] 0, 1 [ $.\n",
    "\n",
    "![Courbe de la fonction sigmoïde](./images/MachineLearning-MLP%20-%20Fonction%20sigmoïde.drawio.png \"Courbe de la fonction sigmoïde\")\n",
    "\n",
    "**Exemple  - la fonction linéaire** : $ f(x) = x $\n",
    "![Couche de la fonction linéaire](./images/MachineLearning-MPL%20-%20Fonction%20linéaire.drawio.png \"Couche de la fonction linéaire\")\n",
    "\n",
    "#### **Perceptron simple**\n",
    "\n",
    "Le perceptron simple est un classificateur binaire basé sur le neurone formel. C'est en 1957, que Frank Rosenblatt proposa dans ses travaux *Perceptron Learning Rule*, des règles décrivant les règles d'apprentissage du perceptron, l'algorithme agence le coefficient des poids lié au vecteur d'entrée le plus optimal possible.\n",
    "\n",
    "#### **Perceptron multicouche**\n",
    "\n",
    "Le perceptron multicouche a été proposé par Paul Werbos en 1974 et mis au point par David Rumelhart en 1986, le perceptron multicouche reprend les travaux du perceptron en y ajoutant l'algorithme de descente de gradient.\n",
    "\n",
    "#### **Dropout :**\n",
    "\n",
    "C'est une méthode utilisée pour mettre aléatoirement le vecteur d'entrée à 0, ce qui permet aux unités de ne pas trop se spécialiser.\n",
    "\n",
    "### Schéma\n",
    "\n",
    "![Image perceptron](./images/MachineLearning-MLP%20-%20Schéma.drawio.png \"Image perceptron\")\n",
    "\n",
    "### Modèle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def perceptron(shape, rate_dropout = 0.):\n",
    "    input = layers.Input(shape = shape, name = \"input\")\n",
    "\n",
    "    fully_connected1 = layers.Flatten(input_shape = shape, name = \"fullyConnected1\")(input)\n",
    "    fully_connected2 = layers.Dense(512, activation = \"sigmoid\", name = \"fullyConnected2\")(fully_connected1)\n",
    "    fully_connected3_1 = layers.Dense(512, activation = \"sigmoid\", name = \"fullyConnected3-1\")(fully_connected2)\n",
    "    fully_connected3_2= layers.Dropout(rate_dropout, name = \"fullyConnected3-2\")(fully_connected3_1)\n",
    "\n",
    "    output = layers.Dense(215, name = \"output\")(fully_connected3_2)\n",
    "\n",
    "    return Model(inputs = input, outputs = output, name = \"Perceptron\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convolutional neural network (CNN)\n",
    "### Définitions\n",
    "\n",
    "Les CNN sont des réseaux de neurones, qui comportent deux parties :\n",
    "- La première partie est du traitement d'image, cette partie va encoder l'image en faisant ressortir des paternes/caractéristiques de l'image dans un vecteur de sorti. L'image est compressée, mais le nombre de dimensions du vecteur en sorti est supérieur à l'image en entrée.\n",
    "- La seconde partie est le classificateur, souvent un pecerptron multicouche, le but de cette couche est de combiner les paternes/caractéristiques extraites pour les classer.\n",
    "\n",
    "![CNN](./images/MachineLearning-CNN%20-%20schema.drawio.png \"Schéma du fonctionnement d'un CNN\")\n",
    "\n",
    "#### Couches Conv\n",
    "\n",
    "La couche de convolution est la couche appliquant un [filtre de convolution](http://mathinfo.alwaysdata.net/2016/11/filtres-de-convolution/) aux pixels d'une image. Elle est souvent représentée comme une fenêtre coulissante, de gauche à droite et de haut en bas, ici la fenêtre étant le filtre.\n",
    "\n",
    "Il est à noter qu'un filtre de convolution s'applique aussi bien à une image qu'un signal temporel.\n",
    "\n",
    "La représentation mathématique d'un filtrage par convolution pour une intensité est la suivante : $$ O(x;y) = \\sum_{i = 0}^{N} \\left( \\sum_{j = 0}^{M} K(i;j) \\times I(x-1+i;y-1+i) \\right) $$\n",
    "\n",
    "> Légende :\n",
    "> $O(x;y)$ : la fonciton qui calcule la convolution d'une position $x$ et $y$ sur une image en nuancier de gris,\n",
    "> $N$ et $M$ : la largeur et la hauteur du filtre de convolution,\n",
    "> $K(i;j)$ : la fonction de renvoie de la valeur du filtre à la position $i$ et $j$,\n",
    "> $I(x-1+i;y-1+i)$ : la fonction de renvoie de l'intentité sur l'image initial.\n",
    "\n",
    "Sur cette couche nous avons retrouvons quatres paramètres :\n",
    "- la taille du filtre : notée $N$ et $M$,\n",
    "- la taille du stride : notée $S$, c'est le nombre de pas de déplacement de la fenêtre a chaque itération sur une image).\n",
    "- La taille de sortie du filtre.\n",
    "- Le \"padding\" : \"same\" signifie qu'un cadre de pixel égale à zéro est ajouté sur les bordures et valide\" signifie qu'aucune modification n'est apportée.\n",
    "\n",
    "![Image de convolution](./images/MachineLearning-CNN%20-%20convolution.drawio.png \"Image de convolution\")\n",
    "\n",
    "#### Couches ReLu\n",
    "\n",
    "La couche ReLu (Rectified Linear Units) est souvent interprété comme une couche d'activation, de la même manière que pour le neurone formel. Dans de nombreux frameworks, la couche ReLu n'existe pas et est directement implémenté dans la couche Conv.\n",
    "\n",
    "> *Exemples de fonction :*\n",
    "> - Remplacer les valeurs négatives par des zéros : $ f(x) = \\left\\{\\begin{array}{ll}0 \\to x \\le  0 \\\\ x \\to x \\gt 0 \\end{array} \\right. $,\n",
    "![Courbe de la fonction Relu](./images/MachineLearning-CNN%20-%20ReLu.drawio.png \"Courbe de la fonction Relu\")\n",
    "> - Fonction de normalisation : $ f(x) = \\frac{x - x_{min}}{x_{max} - x_{min}} $ .\n",
    "\n",
    "#### Couches Pool\n",
    "\n",
    "La couche de Pooling est très souvent placé en sortie de couche Conv après une correction avec la couche ReLu, elle a pour but de réduire la taille de l'image tout en préservant les paternes/caractéristiques essentielles.\n",
    "\n",
    "Il existe plusieurs fonctions de Pooling, la plus utilisée étant le max-pooling.\n",
    "\n",
    "Au même titre que la couche de Conv, il faut imaginer une fenêtre coulissante, contrairement à la couche Conv, nous ne gardons pas la somme du produit entre l'image et le filtre de convolution, mais uniquement la valeur la plus grande.\n",
    "\n",
    "![Image de max-pooling](./images/MachineLearning-CNN%20-%20maxPooling.drawio.png \"Image max-pooling\")\n",
    "\n",
    "#### Couches Fully Connected\n",
    "\n",
    "La couche Fully Connected est un perceptron multicouche."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### AlexNet\n",
    "#### Présentation\n",
    "\n",
    "AlexNet est une architecture de Deep learning conçue par Alex Krizhevsky et Ilya Sutskever à l'université de Toronto publié dans [ImageNet Classification with Deep Convolutional Neural Networks](https://proceedings.neurips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html). L'architecture a remporté l'épreuve ImageNet en 2012.\n",
    "\n",
    "> ImageNet est une base données d'image annotée a destination de travaux de recherche sur la vision par ordinateur.\n",
    "\n",
    "#### Schéma\n",
    "\n",
    "![\"Schema AlexNet\"](./images/MachineLearning-CNN%20-%20AlexNet.drawio.png \"Schema AlexNet\")\n",
    "\n",
    "#### Modèle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def alex_net(shape):\n",
    "    input = layers.Input(shape = shape, name = \"input\")\n",
    "\n",
    "    # Couches de traitement d'image\n",
    "    conv1_1 = layers.Conv2D(filters = 96, kernel_size = 11, strides = 4, activation = \"relu\", name = \"conv1-1\")(input)\n",
    "    conv1_2 = layers.MaxPool2D(pool_size = 3, strides = 2, name = \"conv1-2\")(conv1_1)\n",
    "\n",
    "    conv2_1 = layers.Conv2D(filters = 256, kernel_size = 5, padding = \"same\", activation = \"relu\", name = \"conv2-1\")(conv1_2)\n",
    "    conv2_2 = layers.MaxPool2D(pool_size = 3, strides = 2, name = \"conv2-2\")(conv2_1)\n",
    "\n",
    "    conv3_1 = layers.Conv2D(filters = 384, kernel_size = 3, padding = \"same\", activation = \"relu\", name = \"conv3-1\")(conv2_2)\n",
    "    conv3_2 = layers.Conv2D(filters = 384, kernel_size = 3, padding = \"same\", activation = \"relu\", name = \"conv3-2\")(conv3_1)\n",
    "    conv3_3 = layers.Conv2D(filters = 256, kernel_size = 3, padding = \"same\", activation = \"relu\", name = \"conv3-3\")(conv3_2)\n",
    "    conv3_4 = layers.MaxPool2D(pool_size = 3, strides = 2, name = \"conv3-4\")(conv3_3)\n",
    "\n",
    "    # Couches de classification\n",
    "    fully_connected1 = layers.Flatten(name = \"fullyConnected1\")(conv3_4)\n",
    "\n",
    "    fully_connected2_1 = layers.Dense(4096, activation = \"relu\", name = \"fullyConnected2-1\")(fully_connected1)\n",
    "    fully_connected2_2 = layers.Dropout(0.5, name = \"fullyConnected2-2\")(fully_connected2_1)\n",
    "\n",
    "    fully_connected1_1 = layers.Dense(4096, activation = \"relu\", name = \"fullyConnected3-1\")(fully_connected2_2)\n",
    "    fully_connected1_2 = layers.Dropout(0.5, name = \"fullyConnected3-2\")(fully_connected1_1)\n",
    "\n",
    "    output = layers.Dense(255, name = \"output\")(fully_connected1_2)\n",
    "\n",
    "    return Model(inputs = input, outputs = output, name = \"AlexNet\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visual Geometry Group (VGG)\n",
    "#### Présentation\n",
    "\n",
    "[VGG](https://doi.org/10.48550/arXiv.1409.1556) est un réseau de neurones convolutionnels conçue par K. Simonyan et A. Zisserman à l'université d'Oxord et qui a gagné la compétition ILSVRC (ImageNet Large Scale Visual Recognition Challenge) en 2014.\n",
    "\n",
    "#### Définition\n",
    "\n",
    "Fonction d'activation softmax : Elle converti, un vecteur de $ K $ nombré réel en une distribution de probabilités. La fonciton est notée $  \\sigma(z)_{j} = \\frac{\\mathrm{e}^{\\mathcal{z}_{j}}}{\\sum_{k=1}^{K} \\mathrm{e}^{\\mathcal{z}_{k}}} $ avec $ j \\in {1, ..., K} $.\n",
    "\n",
    "#### Schema\n",
    "\n",
    "VGG16 c'est 13 couches de convolution et 3 couches en fully-connected.\n",
    "VGG19 c'est 16 couches de convolution et 3 couches en fully-connected.\n",
    "\n",
    "![Schémas comparatifs de VGG 16 et 19](./images/MachineLearning-CNN%20-%20VGG.drawio.png \"Schémas comparatifs de VGG 16 et 19\")\n",
    "\n",
    "#### Modèle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def vgg_block(x, depth, number_convolution, number_block):\n",
    "    for i in range(1, number_convolution + 1):\n",
    "        x = layers.Conv2D(filters = depth, kernel_size = 3, padding = \"same\", activation = \"relu\", name = f\"VGG{number_block}-{i}\")(x)\n",
    "\n",
    "    return layers.MaxPool2D(pool_size = 2, strides = 2, name = f\"VGG{number_block}-{number_convolution + 2}\")(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### VGG16"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def vgg_16(shape):\n",
    "    input = layers.Input(shape = shape, name = \"input\")\n",
    "\n",
    "    # Couches de traitement d'image\n",
    "    vgg1 = vgg_block(input, 64, 2, 1)\n",
    "    vgg2 = vgg_block(vgg1, 128, 2, 2)\n",
    "    vgg3 = vgg_block(vgg2, 256, 3, 3)\n",
    "    vgg4 = vgg_block(vgg3, 512, 3, 4)\n",
    "    vgg5 = vgg_block(vgg4, 512, 3, 5)\n",
    "\n",
    "    # Couches de classification\n",
    "    fully_connected1 = layers.Flatten(name = \"fullyConnected1\")(vgg5)\n",
    "    fully_connected2 = layers.Dense(4096, activation = \"relu\", name = \"fullyConnected2\")(fully_connected1)\n",
    "    fully_connected3 = layers.Dense(4096, activation = \"relu\", name = \"fullyConnected3\")(fully_connected2)\n",
    "    output = layers.Dense(255, activation = \"softmax\", name = \"output\")(fully_connected3)\n",
    "\n",
    "    return Model(inputs = input, outputs = output, name = \"VGG16\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### VGG19"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def vgg_19(shape):\n",
    "    input = layers.Input(shape = shape, name = \"input\")\n",
    "\n",
    "    # Couches de traitement d'image\n",
    "    vgg1 = vgg_block(input, 64, 2, 1)\n",
    "    vgg2 = vgg_block(vgg1, 128, 2, 2)\n",
    "    vgg3 = vgg_block(vgg2, 256, 4, 3)\n",
    "    vgg4 = vgg_block(vgg3, 512, 4, 4)\n",
    "    vgg5 = vgg_block(vgg4, 512, 4, 5)\n",
    "\n",
    "    # Couches de classification\n",
    "    fully_connected1 = layers.Flatten(name = \"fullyConnected1\")(vgg5)\n",
    "    fully_connected2 = layers.Dense(4096, activation = \"relu\", name = \"fullyConnected2\")(fully_connected1)\n",
    "    fully_connected3 = layers.Dense(4096, activation = \"relu\", name = \"fullyConnected3\")(fully_connected2)\n",
    "    output = layers.Dense(255, activation = \"softmax\", name = \"output\")(fully_connected3)\n",
    "\n",
    "    return Model(inputs = input, outputs = output, name = \"VGG19\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Residual Network (ResNet)\n",
    "#### Présentation\n",
    "\n",
    "La classe des réseaux de neurones avec résidue ont été indroduit dans l'article [Deep Residual Learning for Image Recognition](https://doi.org/10.48550/arXiv.1512.03385) par Kaiming He, Xiangyu Zhang et al. tous chercheur chez Microsoft en décembre 2015. Le réseau de neurone a été évaluer sur ImageNet de 2012.\n",
    "\n",
    "#### Block résiduel\n",
    "\n",
    "Dans un réseau de neurone avec résidue, il faut imaginer plusieurs sous réseau empiler les une après les autres.\n",
    "\n",
    "![Schéma d'un résiduel bloc](./images/MachineLearning-CNN%20-%20Residual%20block.drawio.png \"Schéma d'un résiduel bloc\")\n",
    "\n",
    "Chaque sous-réseau est appelé bloc résiduel, chaque bloc utilise la technique des connexions à saut, cela signifie que l'entrée du bloc est additionné avec la sortie du bloc. La fonction résiduel est notée de la manière suivante : $F(x) := H(x) - x \\Leftrightarrow H(x) := F(x) + x$, avec $x$ l'entrée du bloc et $F(x)$ la sortie calculée du bloc et $H(x)$ la sortie du bloc avec résidus.\n",
    "\n",
    "Lorsque les dimensions du vecteur d'entrée et le vecteur calculé par le bloc ne coïncide pas, il existe plusieurs méthodes :\n",
    "- Nous appliquons une couche de convolution au vecteur d'entrée afin de réduire les dimensions du vecteur.\n",
    "- Ne pas appliquer l'addition entre les vecteurs.\n",
    "\n",
    "#### Schéma\n",
    "\n",
    "![Schéma comparatif de ResNet 34 et 50](./images/MachineLearning-CNN%20-%20ResNet.drawio.png \"Schéma comparatif de ResNet 34 et 50\")\n",
    "\n",
    "#### Modèle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def conv_block(x, name, f, k, s = 1, with_relu = True):\n",
    "    m = layers.Conv2D(filters = f, kernel_size = k, strides = s, padding = \"same\", name = f\"{name}-1\")(x)\n",
    "    m = layers.BatchNormalization(name = f\"{name}-2\")(m)\n",
    "\n",
    "    if with_relu:\n",
    "        m = layers.ReLU(name = f\"{name}-3\")(m)\n",
    "\n",
    "    return m\n",
    "\n",
    "def residual_block(x, number_block, configs, repetition, is_residual = True):\n",
    "    name = f\"{'residual' if is_residual else 'plain'}{number_block}\"\n",
    "\n",
    "    for i in range(1, repetition+1):\n",
    "        n = 0\n",
    "        x_skip = x\n",
    "        for config in configs:\n",
    "            n += 1\n",
    "\n",
    "            x = conv_block(\n",
    "                x = x,\n",
    "                name = f\"{name}-{i}-{n}\",\n",
    "                f = config[\"f\"],\n",
    "                k = config[\"k\"],\n",
    "                s = 2 if i == 1 and n == 1 and number_block > 1 else 1,\n",
    "                with_relu = len(configs) != n or is_residual == False\n",
    "            )\n",
    "\n",
    "        if is_residual and x.shape == x_skip.shape:\n",
    "            n += 1\n",
    "            x = layers.Add(name = f\"{name}-{i}-{n}\")([x_skip, x])\n",
    "\n",
    "        x = layers.ReLU(name = f\"{name}-{i}-{n + 1}\")(x)\n",
    "\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Avec 34 couches"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def resnet_34_layers(shape, is_residual = True):\n",
    "    input = layers.Input(shape = shape, name = \"input\")\n",
    "    name = f\"{'residual' if is_residual else 'plain'}\"\n",
    "\n",
    "    # Couches de traitement d'image\n",
    "    conv1_1 = layers.Conv2D(filters = 64, kernel_size = 7, strides = 2, padding = \"same\", name = f\"conv1-1\")(input)\n",
    "    conv1_2 = layers.MaxPool2D(pool_size = 3, strides = 2, padding = \"same\", name = f\"conv1-2\")(conv1_1)\n",
    "\n",
    "    residual_block1 = residual_block(conv1_2, 1, [\n",
    "        { \"k\": 3, \"f\": 64 },\n",
    "        { \"k\": 3, \"f\": 64 }\n",
    "    ], 3 , is_residual)\n",
    "\n",
    "    residual_block2 = residual_block(residual_block1, 2, [\n",
    "        { \"k\": 3, \"f\": 128 },\n",
    "        { \"k\": 3, \"f\": 128 }\n",
    "    ], 4, is_residual)\n",
    "\n",
    "    residual_block3 = residual_block(residual_block2, 3, [\n",
    "        { \"k\": 3, \"f\": 256 },\n",
    "        { \"k\": 3, \"f\": 256 }\n",
    "    ], 6, is_residual)\n",
    "\n",
    "    residual_block4 = residual_block(residual_block3, 4, [\n",
    "        { \"k\": 3, \"f\": 512 },\n",
    "        { \"k\": 3, \"f\": 512 }\n",
    "    ], 3, is_residual)\n",
    "\n",
    "    conv2 = layers.GlobalAvgPool2D(name = \"conv2\")(residual_block4)\n",
    "\n",
    "    # Couches de classification\n",
    "    output = layers.Dense(215, activation = \"softmax\")(conv2)\n",
    "\n",
    "    return Model(inputs = input, outputs = output, name = \"ResNet-34\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Avec 50 couches"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def resnet_50_layers(shape, is_residual = True):\n",
    "    input = layers.Input(shape = shape, name = \"input\")\n",
    "\n",
    "    # Couches de traitement d'image\n",
    "    conv1_1 = layers.Conv2D(filters = 64, kernel_size = 7, strides = 2, padding = \"same\", name = f\"conv-1-1\")(input)\n",
    "    conv1_2 = layers.MaxPool2D(pool_size = 3, strides = 2, padding = \"same\", name = f\"conv-1-2\")(conv1_1)\n",
    "\n",
    "    residual_block1 = residual_block(conv1_2, 1, [\n",
    "        { \"k\": 1, \"f\": 64, \"s\": 1 },\n",
    "        { \"k\": 3, \"f\": 64, \"s\": 1 },\n",
    "        { \"k\": 1, \"f\": 4*64, \"s\": 1 }\n",
    "    ], 3, is_residual)\n",
    "\n",
    "    residual_block2 = residual_block(residual_block1, 2, [\n",
    "        { \"k\": 1, \"f\": 128, \"s\": 2 },\n",
    "        { \"k\": 3, \"f\": 128, \"s\": 1 },\n",
    "        { \"k\": 1, \"f\": 4*128, \"s\": 1 }\n",
    "    ], 4, is_residual)\n",
    "\n",
    "    residual_block3 = residual_block(residual_block2, 3, [\n",
    "        { \"k\": 1, \"f\": 256, \"s\": 2 },\n",
    "        { \"k\": 3, \"f\": 256, \"s\": 1 },\n",
    "        { \"k\": 1, \"f\": 4*256, \"s\": 1 }\n",
    "    ], 6, is_residual)\n",
    "\n",
    "    residual_block4 = residual_block(residual_block3, 4, [\n",
    "        { \"k\": 1, \"f\": 512, \"s\": 2 },\n",
    "        { \"k\": 3, \"f\": 512, \"s\": 1 },\n",
    "        { \"k\": 1, \"f\": 4*512, \"s\": 1 }\n",
    "    ], 3, is_residual)\n",
    "\n",
    "    conv2 = layers.GlobalAvgPool2D(name = \"conv2\")(residual_block4)\n",
    "\n",
    "    # Couches de classification\n",
    "    output = layers.Dense(215, activation = \"softmax\")(conv2)\n",
    "\n",
    "    return Model(inputs = input, outputs = output, name = \"ResNet-34\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MobilNet\n",
    "#### Présentation\n",
    "\n",
    "La classe de réseau de neurone MobilNet a été publier en 2017 dans l'article [MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://doi.org/10.48550/arXiv.1704.04861 \"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\") par Andrew G. Howard, Menglong Zhu et al.\n",
    "\n",
    "La deuxième version a été publier en 2019 dans l'article [MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://doi.org/10.48550/arXiv.1801.04381 \"MobileNetV2: Inverted Residuals and Linear Bottlenecks\") par Mark Sandler, Andrew Howard et al.\n",
    "\n",
    "Cette classe de réseau a été créée pour répondre au besoin d'utiliser la vision par ordinateur sur mobiles et autre appareille embarquées n'ayant pas la même puissance qu'un PC classique.\n",
    "\n",
    "#### Convolution Depthwise\n",
    "\n",
    "La convolution classique applique un filtre de convolution sur tous les canaux d'entrée en même temps.\n",
    "\n",
    "La convolution deepthwise applique un filtre sur chaque canal d'entrée séparé, la logique apliqué est la suivante :\n",
    "- Un tenseur d'entrée à 3 dimensions est divisé en canaux distincts.\n",
    "- Pour chaque canal, l'entrée est convoluée avec un filtre (2D).\n",
    "- La sortie de chaque canal est ensuite empilée pour obtenir la sortie sur l'ensemble du tenseur 3D.\n",
    "\n",
    "![Schéma comparatif entre la convolution et la convolution depthwise](./images/MachineLearning-CNN%20-%20Depthwise.drawio.png \"Schéma comparatif entre la convolution et la convolution depthwise\")\n",
    "\n",
    "#### ReLu6\n",
    "\n",
    "La fonction relue reprend la fonction ReLu précédement décrite mais la valeur maximum est à 6.\n",
    "\n",
    "Toutes les valeurs négatives sont remplacé par zéros et toutes les valeurs au dessus de six sont remplacé par six : $ f(x) = \\left\\{\\begin{array}{ll} 0 \\to x \\le  0 \\\\ x \\to 0 > x < 6 \\\\ 6 \\to x \\geq 6 \\end{array} \\right. $.\n",
    "\n",
    "![Courbe de la fonction Relu plafonnée à 6](./images/MachineLearning-CNN%20-%20ReLu%206.drawio.png \"Courbe de la fonction Relu plafonnée à 6\")\n",
    "\n",
    "#### Linear BottleNeck\n",
    "\n",
    "Le goulot d'étranglement linéaire est dans le cas d'un réseau MobileNet V2 un bloc résiduel inversé. Cela signifie que les dimensions des fenêtres sont : large → étroit → large.\n",
    "\n",
    "Le bloc résiduel classique est le suivant : étroit → large → étroit.\n",
    "\n",
    "![Schéma d'un goulot d'étranglement pour  MobileNet V2](./images/MachineLearning-CNN%20-%20Linear%20Bottlenecks.drawio.png \"Schéma d'un goulot d'étranglement pour  MobileNet V2\")\n",
    "\n",
    "#### Modèle\n",
    "##### V1\n",
    "\n",
    "![Schéma du MobileNet V1](./images/MachineLearning-CNN%20-%20MobileNet%20V1.drawio.png \"Schéma du MobileNet V1\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def depth_wise_block(x, f, s, number_block):\n",
    "    x = layers.DepthwiseConv2D(kernel_size = 3, strides = s, padding = 'same', activation = \"relu\", name = f\"depthWise{number_block}-1\")(x)\n",
    "    return layers.Conv2D(filters = f, kernel_size = 1, padding = 'same', activation = \"relu\", name = f\"depthWise{number_block}-2\")(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mobilenet_v1(shape):\n",
    "    input = layers.Input(shape = shape, name = \"input\")\n",
    "\n",
    "    # Couches de traitement d'image\n",
    "    conv1 = layers.Conv2D(filters = 32, kernel_size = 3, strides = 2, padding = 'same', activation = \"relu\", name = \"conv1\")(input)\n",
    "\n",
    "    depthWise1 = depth_wise_block(conv1, 64, 1, 1)\n",
    "\n",
    "    depthWise2 = depth_wise_block(depthWise1, 128, 2, 2)\n",
    "    depthWise3 = depth_wise_block(depthWise2, 128, 1, 3)\n",
    "\n",
    "    depthWise4 = depth_wise_block(depthWise3, 256, 2, 4)\n",
    "    depthWise5 = depth_wise_block(depthWise4, 256, 1, 5)\n",
    "\n",
    "    depthWise6 = depth_wise_block(depthWise5, 512, 2, 6)\n",
    "    depthWise7 = depth_wise_block(depthWise6, 512, 1, 7)\n",
    "    depthWise8 = depth_wise_block(depthWise7, 512, 1, 8)\n",
    "    depthWise9 = depth_wise_block(depthWise8, 512, 1, 9)\n",
    "    depthWise10 = depth_wise_block(depthWise9, 512, 1, 10)\n",
    "    depthWise11 = depth_wise_block(depthWise10, 512, 1, 11)\n",
    "\n",
    "    depthWise12 = depth_wise_block(depthWise11, 1024, 2, 12)\n",
    "    depthWise13 = depth_wise_block(depthWise12, 1024, 1, 13)\n",
    "\n",
    "    # Couches de classification\n",
    "    fullyConnected1 = layers.Flatten(name = \"fullyConnected1\")(depthWise13)\n",
    "    fullyConnected2 = layers.Dense(1024, activation = \"relu\", name = f\"fullyConnected2\")(fullyConnected1)\n",
    "    output = layers.Dense(255, activation = \"softmax\", name = \"output\")(fullyConnected2)\n",
    "\n",
    "    return Model(inputs = input, outputs = output, name = \"MobileNetV1\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### v2\n",
    "\n",
    "![Schéma du MobilNet V2](./images/MachineLearning-CNN%20-%20MobileNet%20V2.drawio.png \"Schéma du MobilNet V2\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def bottleneck(x, t, c, s, block_number):\n",
    "    m = layers.Conv2D(filters = x.shape[-1] * t, kernel_size = 1, padding = \"same\", name = f\"bottleneck{block_number}-1\")(x)\n",
    "    m = layers.BatchNormalization(name = f\"bottleneck{block_number}-2\")(m)\n",
    "    m = layers.ReLU(max_value = 6., name = f\"bottleneck{block_number}-3\")(m)\n",
    "\n",
    "    m = layers.DepthwiseConv2D(kernel_size = 3, strides = s, padding = \"same\", name = f\"bottleneck{block_number}-4\")(m)\n",
    "    m = layers.BatchNormalization(name = f\"bottleneck{block_number}-5\")(m)\n",
    "    m = layers.ReLU(max_value = 6., name = f\"bottleneck{block_number}-6\")(m)\n",
    "\n",
    "    m = layers.Conv2D(filters = c, kernel_size = 1, padding = \"same\", name = f\"bottleneck{block_number}-7\")(m)\n",
    "    m = layers.BatchNormalization(name = f\"bottleneck{block_number}-8\")(m)\n",
    "\n",
    "    if s == 1 and x.shape == m.shape:\n",
    "        m = layers.Add(name = f\"bottleneck{block_number}-9\")([m, x])\n",
    "\n",
    "    return m"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def mobilenet_v2(shape):\n",
    "    input = layers.Input(shape = shape, name = \"inputLayers\")\n",
    "\n",
    "    # Couches de traitement d'image\n",
    "    conv1_1 = layers.Conv2D(filters = 32, kernel_size = 3, strides = 2, padding = \"same\", name = \"conv1-1\")(input)\n",
    "    conv1_2 = layers.BatchNormalization(name = \"conv1-2\")(conv1_1)\n",
    "    conv1_3 = layers.ReLU(max_value = 6., name = \"conv1-3\")(conv1_2)\n",
    "\n",
    "    bottleneck1 = bottleneck(conv1_3, 1, 16, 1, 1)\n",
    "\n",
    "    bottleneck2 = bottleneck(bottleneck1, 6, 24, 2, 2)\n",
    "    bottleneck3 = bottleneck(bottleneck2, 6, 24, 1, 3)\n",
    "\n",
    "    bottleneck4 = bottleneck(bottleneck3, 6, 32, 2, 4)\n",
    "    bottleneck5 = bottleneck(bottleneck4, 6, 32, 1, 5)\n",
    "    bottleneck6 = bottleneck(bottleneck5, 6, 32, 1, 6)\n",
    "\n",
    "    bottleneck7 = bottleneck(bottleneck6, 6, 64, 2, 7)\n",
    "    bottleneck8 = bottleneck(bottleneck7, 6, 64, 1, 8)\n",
    "    bottleneck9 = bottleneck(bottleneck8, 6, 64, 1, 9)\n",
    "    bottleneck10 = bottleneck(bottleneck9, 6, 64, 1, 10)\n",
    "\n",
    "    bottleneck11 = bottleneck(bottleneck10, 6, 96, 1, 11)\n",
    "    bottleneck12 = bottleneck(bottleneck11, 6, 96, 1, 12)\n",
    "    bottleneck13 = bottleneck(bottleneck12, 6, 96, 1, 13)\n",
    "\n",
    "    bottleneck14 = bottleneck(bottleneck13, 6, 160, 2, 14)\n",
    "    bottleneck15 = bottleneck(bottleneck14, 6, 160, 1, 15)\n",
    "    bottleneck16 = bottleneck(bottleneck15, 6, 160, 1, 16)\n",
    "\n",
    "    bottleneck17 = bottleneck(bottleneck16, 6, 320, 1, 17)\n",
    "\n",
    "    conv2 = layers.Conv2D(filters = 1280, kernel_size = 1, strides = 1, activation = \"relu\", name = f\"conv2\")(bottleneck17)\n",
    "    global_avg_pool1 = layers.GlobalAveragePooling2D(name = f\"globalAvgPool1\")(conv2)\n",
    "\n",
    "    # Couches de classification\n",
    "    output = layers.Dense(255, activation = \"softmax\", name = \"output\")(global_avg_pool1)\n",
    "\n",
    "    return Model(inputs = input, outputs = output, name = \"MobileNetV2\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4 - Phase d'entraînement\n",
    "## Principe d'entrainement\n",
    "\n",
    "https://www.lebigdata.fr/machine-learning-entrainement-ia\n",
    "\n",
    "\n",
    "### époque (epoch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Présentation des indicateurs de performances\n",
    "\n",
    "Cette partie a été rédigé sur des travaux antérieurs [HumanForYou - CESI A4](https://github.com/Scordragours/Projet-IA-A4/blob/master/Groupe%20n%C2%B04%20-%20Livrable%20n%C2%B01%20:%20Compte%20rendu%20analyse%20de%20donn%C3%A9es.ipynb).\n",
    "\n",
    "### Définition\n",
    "\n",
    "En Machine Learning, la bonne manière de procéder consiste à se baser sur des indicateurs mathématiques précis et concrets ouvrant la porte aux interprétations humaines. Généralement dans ce type de problèmes de classification, des indicateurs tels que des métriques de performance ou encore des courbes de comparaisons sont très utilisés.\n",
    "\n",
    "Chaque indicateur de cette partie sera donc accompagnée d'une rapide description ainsi qu'une explication sur son utilisation et sur le résultat obtenu dans notre contexte.\n",
    "\n",
    "![\"Visualisation des bonnes et mauvaise données\"](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRaefwz7ZSNyFZeO8Urtnjj58MgDKFzRV5aE0WNoXNn6ejBy3ZvVDwQVL8N081CpvTfOJY&usqp=CAU \"Visualisation des bonnes et mauvaise données\")\n",
    "\n",
    "### Matrice de confusion\n",
    "\n",
    "La matrice est de confusion est aujourd'hui l'un des outils les plus utilisés pour évaluer les performances d'un modèle de classification. Celle-ci présente un système de classes associées chacune à une valeur de représentation de cette classe suite à l'entrainement avec un modèle de prédictions. Il est à noter que ce type de matrice fonctionne aussi bien pour des problèmes de classification à 2 classes (binaires) ou plus.\n",
    "\n",
    "Veuillez trouver ci-dessous un exemple de matrice de prédiction binaire :\n",
    "![\"Matrice de confusion binaire\"](https://docs.microsoft.com/fr-fr/dynamics365/finance/finance-insights/media/tn-fn.png \"Matrice de confusion binaire\")\n",
    "\n",
    "Comme présenté dans la figure, dans le cas binaire les classes sont :\n",
    "- ***TP*** : les valeurs prédites positives par le modèle et qui se trouvent être positives au final (bonne prédiction)\n",
    "- ***TN*** : les valeurs prédites positives par le modèle et qui se trouvent être négatives au final (mauvaise prédiction)\n",
    "- ***FP*** : les valeurs prédites négatives par le modèle et qui se trouvent être positives au final (mauvaise prédiction)\n",
    "- ***FN*** : les valeurs prédites négatives par le modèle et qui se trouvent être négatives au final (bonne prédiction)\n",
    "\n",
    "Ici les expliquation sont pour des cas binaires, mais le fonctionnement est identique.\n",
    "\n",
    "### Sensibilité, Recall, TPR\n",
    "\n",
    "La sensibilité mesure la proportion de vrais positifs parmi tous les cas positifs. Le calcule est le suivant : $Recall = {{TP} \\over {TP \\, + \\, FN}}$.\n",
    "\n",
    "### Spécificité, TNR\n",
    "\n",
    "La spécificité mesure la proportion de vrais négatifs parmi tous les cas négatifs. Le calcule est le suivant : $TNR = {{TN} \\over {TN \\, + \\, FP}}$.\n",
    "\n",
    "### Fall out, FPR\n",
    "\n",
    "Le Fall out mesure la proportion de faux positifs parmi tous les cas négatifs. Le calcul est le suivant : $FPR = {{FP} \\over {TN \\, + \\, FP}}$.\n",
    "\n",
    "### FNR\n",
    "\n",
    "Le FNR mesure la proportion de faux négatifs parmi tous les cas positifs. Le calcule est le suivant : $FNR = {{FN} \\over {FN \\, + \\, TP}}$.\n",
    "\n",
    "### Précision, PPV\n",
    "\n",
    "La précision mesure la proportion de vrais positifs parmi tous les résultats positifs. Le calcule est le suivant : $Precision = {{TP} \\over {TP+FP}}$.\n",
    "\n",
    "### FDR\n",
    "\n",
    "Le FDR mesure la proportion de fausses découvertes parmi toutes les découvertes positives. Le calcule est le suivant : $FDR = 1-PPV{{FP} \\over {TP \\, + \\, FP}}$.\n",
    "\n",
    "### NPV\n",
    "\n",
    "Len NPV mesure la proportion de vrais négatifs parmi tous les résultats négatifs. Le calcule est le suivant : $NPV = {{TN} \\over {TN \\, + \\, FN}}$.\n",
    "\n",
    "### FOR\n",
    "\n",
    "Le FOR mesure la probabilité qu'un résultat négatif prédit soit en réalité un vrai négatif. Le calcule est le suivant : $FOR = 1-NPV{{FN} \\over {TN \\, + \\, FN}}$.\n",
    "\n",
    "### Accuracy, Acc\n",
    "\n",
    "L'accurary mesure le rapport entre le nombre de prédictions correctes et le nombre total d'observations. Le calcule est le suivant :  $Accuracy = {{TP \\, + \\, TN} \\over {TP \\, + \\, TN \\, + \\, FP \\, + \\, FN}}$.\n",
    "\n",
    "### F1-score\n",
    "\n",
    "Le score F1 représente une évaluation de la performance de l'algorithme. Ce score est la moyenne harmonique de la précision et du rappel (cf: image ci-dessous).\n",
    "\n",
    "Lorsque deux modèles ont une précision élevée et un faible rappel ou inversement, la comparaison peut être plus compliquée. C'est pourquoi, dans ce type de situation, il est préférable d'utiliser le score F1 car il permet de mesurer ces deux paramètres simultanément.\n",
    "\n",
    "Le calcule est le suivant : $F1-Score = 2 {{Precision \\, * \\, Recall} \\over {(Precision \\, + \\, Recall)}}$.\n",
    "\n",
    "### Courbe ROC\n",
    "\n",
    "La courbe ROC est un autre moyen d'évaluer un classifieur. Elle confronte le taux de vrai positif (TPR ou recall) au taux de faux positif (FPR).\n",
    "\n",
    "### AUC\n",
    "\n",
    "Pour la courbe ROC, un grand taux de vrais positifs implique beaucoup de faux positifs. La diagonale en pointillée représente la courbe ROC d'un classificateur aléatoire. Un classificateur idéal s'en écarte au maximum dans le coin supérieur gauche.\n",
    "\n",
    "C'est pourquoi on utilise comme métrique de comparaison l'air sous la courbe ROC, nommé AUC, que l'on souhaite la plus proche possible de 1."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Callback\n",
    "\n",
    "Les Callback sont des moyens de customiser le comportement d'un modèle durant les phases d'évaluations.\n",
    "\n",
    "Dans notre cas, nous avons décidé de les utiliser pour :\n",
    "- Sauvegarder des informations pour Tensorboard.\n",
    "- Sauvegardes des poids.\n",
    "- Stopper l'entrainement (Early stopping).\n",
    "- Création de matrice de confusion."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Information d'entrainement pour Tensorboard\n",
    "Le callback [TensorBoard](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard) vas enregistrer des informations qui vont permettre à Tenserboard de construire les courbes de progressions de la précision et de la perte."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir = f\"logs/fit/{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
    "    histogram_freq = 1\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Sauvegarde des poids\n",
    "\n",
    "Le callback [ModelCheckpoint](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) garde en mémoire le poids des modèles. Ils pourront donc être rechargés sur un modèle de même structure à la prochaine exécutions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = \"logs/weight/cp.ckpt\",\n",
    "    monitor = \"val_loss\",\n",
    "    save_weights_only = True,\n",
    "    save_best_only = True,\n",
    "    verbose = 1\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stopper l'entrainement (Early stopping)\n",
    "\n",
    "Le callback [EarlyStopping](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) va, afin d'éviter le sur-apprentissage, limiter le nombre d'époques. Dès qu'il n'y a pas de progrès pendant un nombre d'époques supérieur à la patience, on se trouve face à un sur-apprentissage et on arrête l'exécution."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Création de la matrice de confusion\n",
    "\n",
    "Ici, on construit une matrice de confusion entre chaque époque avec sklearn qui est convertie en png pour la sauvegarder puis l'afficher dans Tensorboard.\n",
    "\n",
    "Code basé sur le travail de Vincent Havard."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#fonctions utiles\n",
    "def plot_to_image(figure):\n",
    "    \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "def plot_confusion_matrix(cm_main, class_names, figsize=(5, 5), accuracy_score=None):\n",
    "    #Crée un matplotlib plot à partir d'une matrice de confusion numérique et des labels associée\n",
    "    figure = plt.figure(figsize=figsize)\n",
    "    ax = plt.imshow(cm_main, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    str_title = \"Confusion matrix\"\n",
    "    if accuracy_score is not None:\n",
    "        str_title = str_title + f\" acc:{np.round(accuracy_score*100, decimals=3)}%\"\n",
    "    plt.title(str_title)\n",
    "\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "\n",
    "\n",
    "    threshold = 0.5\n",
    "    # write labels\n",
    "    for i, j in itertools.product(range(cm_main.shape[0]), range(cm_main.shape[1])):\n",
    "        val = cm_main[i, j]\n",
    "        if val >= 0:\n",
    "            color = \"white\" if cm_main[i, j] > threshold else \"black\"\n",
    "            plt.text(j, i, cm_main[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def model_to_confusion_matrix(model, x_test, y_test, class_names, plotIt = True):\n",
    "    y_pred_onehot = model.predict(x_test)\n",
    "    y_pred = np.argmax(y_pred_onehot, axis=1)\n",
    "    # Calculate the confusion matrix.\n",
    "    cm_norm = None\n",
    "    figure = None\n",
    "    if y_test.ndim > 1:\n",
    "        y_test = y_test.squeeze()\n",
    "\n",
    "    if y_pred.ndim > 1:\n",
    "        y_pred = y_pred.squeeze()\n",
    "\n",
    "    idx = np.unique(np.concatenate((y_test, y_pred)))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    # compute normalzed confusion matrix\n",
    "    cm_norm = confusion_matrix(y_test, y_pred, normalize=\"true\")\n",
    "    cm_norm = np.round(cm_norm, decimals=2)\n",
    "    # print(\"cm_norm\", cm_norm)\n",
    "    if plotIt:\n",
    "        cm_main = cm_norm\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        n=len(class_names)\n",
    "        figure = plot_confusion_matrix(cm_main, class_names, figsize=(n,n), accuracy_score=acc)\n",
    "    # cm, y_pred, y_pred_onehot, (optional: cm_norm, figure)\n",
    "    return cm, y_pred, y_pred_onehot, cm_norm, figure"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#définition du callback perso\n",
    "class ConfusionMatrixCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, x_test, y_test, class_names, file_writer_cm):\n",
    "\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.class_names = class_names\n",
    "        self.file_writer_cm = file_writer_cm\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        _, _, _, _, figure = model_to_confusion_matrix(self.model, self.x_test,self.y_test,self.class_names)\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        cm_image = plot_to_image(figure)\n",
    "\n",
    "        # Log the confusion matrix as an image summary.\n",
    "        with self.file_writer_cm.as_default():\n",
    "\n",
    "            tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)\n",
    "            self.file_writer_cm.flush()\n",
    "            print(self.file_writer_cm)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5 - Exécution des Modèles\n",
    "## Automatisation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from csv import DictWriter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def accuracy_save(path_models, n_dropout, nb_epoch, min_delta, patience, accuracy ):\n",
    "    # Import DictWriter class from CSV module\n",
    "\n",
    "    # list of column names\n",
    "    field_names = ['N_Dropout','Nb_Epoch', 'Min_Delta', 'Patience', 'Accuracy']\n",
    "\n",
    "    with open(f\"{path_models}/Graphe.csv\", 'a') as f_object:\n",
    "        writer_object = DictWriter(f_object, fieldnames=field_names)\n",
    "\n",
    "        writer_object.writerow({\n",
    "            'N_Dropout':n_dropout,\n",
    "            'Nb_Epoch': nb_epoch,\n",
    "            'Min_Delta':min_delta,\n",
    "            'Patience':patience,\n",
    "            'Accuracy': accuracy\n",
    "        })\n",
    "\n",
    "        f_object.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def auto_models(name, model, dataset, config):\n",
    "    path_models = f\"../models/{name}\"\n",
    "\n",
    "    class_names =  dataset[\"train\"].class_names\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    for images, labels in dataset[\"validation\"].take(-1):\n",
    "        x_test = images.numpy()\n",
    "        y_test = labels.numpy()\n",
    "\n",
    "    model.compile(\n",
    "        optimizer = \"adam\",\n",
    "        loss = losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "        metrics = [ \"accuracy\" ]\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(path_models):\n",
    "        os.mkdir(path_models)\n",
    "\n",
    "        tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "            log_dir = f\"{path_models}/tensorBoard/{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "        )\n",
    "\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath = f\"{path_models}/weight/cp.ckpt\",\n",
    "            monitor = \"val_loss\",\n",
    "            save_weights_only = config[\"save_weights_only\"],\n",
    "            save_best_only = config[\"save_best_only\"]\n",
    "        )\n",
    "\n",
    "        early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            min_delta = config[\"min_delta\"],\n",
    "            patience = config[\"patience\"]\n",
    "        )\n",
    "\n",
    "        confusionMatrix_callback = ConfusionMatrixCallback(\n",
    "            x_test = x_test,\n",
    "            y_test = y_test,\n",
    "            class_names = class_names,\n",
    "            file_writer_cm = tf.summary.create_file_writer(f\"{path_models}/confusionMatrix\")\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            dataset[\"train\"],\n",
    "            validation_data = dataset[\"validation\"],\n",
    "            callbacks = [\n",
    "                tensorboard_callback,\n",
    "                cp_callback,\n",
    "                confusionMatrix_callback,\n",
    "                early_stopping_callback\n",
    "            ],\n",
    "            batch_size = 1,\n",
    "            epochs = config[\"epochs\"]\n",
    "        )\n",
    "\n",
    "        acc = history.history['accuracy']\n",
    "        val_acc = history.history['val_accuracy']\n",
    "\n",
    "        print(acc, val_acc)\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(dataset[\"test\"], verbose = 2)\n",
    "    print(test_loss, test_acc)\n",
    "\n",
    "    accuracy_save(\n",
    "        path_models,\n",
    "        config[\"dropout\"],\n",
    "        config[\"epochs\"],\n",
    "        config[\"min_delta\"],\n",
    "        config[\"patience\"],\n",
    "        test_acc\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exécution sans data augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_set, validation_set, test_set = loadDataSet(path_datasets, (256, 256))\n",
    "\n",
    "config_colored = {\n",
    "    \"train\": train_set,\n",
    "    \"validation\": validation_set,\n",
    "    \"test\": test_set\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perceptron"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_models(\n",
    "    name = \"perceptron-colored\",\n",
    "    model = perceptron((256, 256, 3), 0.5),\n",
    "    dataset = config_colored,\n",
    "    config = {\n",
    "        \"save_weights_only\": True,\n",
    "        \"save_best_only\": True,\n",
    "        \"min_delta\": 0,\n",
    "        \"patience\": 5,\n",
    "        \"epochs\": 20,\n",
    "        \"dropout\": 0.3\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### AlexNet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_models(\n",
    "    name = \"alexNet-colored\",\n",
    "    model = alex_net((256, 256, 3)),\n",
    "    dataset = config_colored,\n",
    "    config = {\n",
    "        \"save_weights_only\": True,\n",
    "        \"save_best_only\": True,\n",
    "        \"min_delta\": 0,\n",
    "        \"patience\": 5,\n",
    "        \"epochs\": 20,\n",
    "        \"dropout\": 0.3\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### VGG 16"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_models(\n",
    "    name = \"vgg16-colored\",\n",
    "    model = vgg_16((512, 512, 3)),\n",
    "    dataset = config_colored,\n",
    "    config = {\n",
    "        \"save_weights_only\": True,\n",
    "        \"save_best_only\": True,\n",
    "        \"min_delta\": 0,\n",
    "        \"patience\": 5,\n",
    "        \"epochs\": 20,\n",
    "        \"dropout\": 0.3\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### VGG 19"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_models(\n",
    "    name = \"vgg19-colored\",\n",
    "    model = vgg_19((512, 512, 3)),\n",
    "    dataset = config_colored,\n",
    "    config = {\n",
    "        \"save_weights_only\": True,\n",
    "        \"save_best_only\": True,\n",
    "        \"min_delta\": 0,\n",
    "        \"patience\": 5,\n",
    "        \"epochs\": 20,\n",
    "        \"dropout\": 0.3\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ResNet 34 - Plain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_models(\n",
    "    name = \"resNet34-plain-colored\",\n",
    "    model = resnet_34_layers((512, 512, 3), False),\n",
    "    dataset = config_colored,\n",
    "    config = {\n",
    "        \"save_weights_only\": True,\n",
    "        \"save_best_only\": True,\n",
    "        \"min_delta\": 0,\n",
    "        \"patience\": 5,\n",
    "        \"epochs\": 20,\n",
    "        \"dropout\": 0.3\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ResNet 34 - Residual"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_models(\n",
    "    name = \"resNet34-residual-colored\",\n",
    "    model = resnet_34_layers((512, 512, 3), True),\n",
    "    dataset = config_colored,\n",
    "    config = {\n",
    "        \"save_weights_only\": True,\n",
    "        \"save_best_only\": True,\n",
    "        \"min_delta\": 0,\n",
    "        \"patience\": 5,\n",
    "        \"epochs\": 20,\n",
    "        \"dropout\": 0.3\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ResNet 50 - Plain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_models(\n",
    "    name = \"resNet50-plain-colored\",\n",
    "    model = resnet_50_layers((512, 512, 3), False),\n",
    "    dataset = config_colored,\n",
    "    config = {\n",
    "        \"save_weights_only\": True,\n",
    "        \"save_best_only\": True,\n",
    "        \"min_delta\": 0,\n",
    "        \"patience\": 5,\n",
    "        \"epochs\": 20,\n",
    "        \"dropout\": 0.3\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ResNet 50 - Residual"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_models(\n",
    "    name = \"resNet50-residual-colored\",\n",
    "    model = resnet_50_layers((512, 512, 3), True),\n",
    "    dataset = config_colored,\n",
    "    config = {\n",
    "        \"save_weights_only\": True,\n",
    "        \"save_best_only\": True,\n",
    "        \"min_delta\": 0,\n",
    "        \"patience\": 5,\n",
    "        \"epochs\": 20,\n",
    "        \"dropout\": 0.3\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MobileNet V1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_models(\n",
    "    name = \"mobileNetV1-colored\",\n",
    "    model = mobilenet_v1((512, 512, 3)),\n",
    "    dataset = config_colored,\n",
    "    config = {\n",
    "        \"save_weights_only\": True,\n",
    "        \"save_best_only\": True,\n",
    "        \"min_delta\": 0,\n",
    "        \"patience\": 5,\n",
    "        \"epochs\": 20,\n",
    "        \"dropout\": 0.3\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MobileNet V2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_models(\n",
    "    name = \"mobileNetV2-colored\",\n",
    "    model = mobilenet_v2((512, 512, 3)),\n",
    "    dataset = config_colored,\n",
    "    config = {\n",
    "        \"save_weights_only\": True,\n",
    "        \"save_best_only\": True,\n",
    "        \"min_delta\": 0,\n",
    "        \"patience\": 5,\n",
    "        \"epochs\": 20,\n",
    "        \"dropout\": 0.3\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exécution avec data augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_augmented_colored_set, validation_augmented_colored_set, test_augmented_colored_set = loadDataSet(path_datasets_augmented_trainTest, (512, 512))\n",
    "\n",
    "config_augmented_colored = {\n",
    "    \"train\": train_augmented_colored_set,\n",
    "    \"validation\": validation_augmented_colored_set,\n",
    "    \"test\": test_augmented_colored_set\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perceptron"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_models(\n",
    "    name = \"perceptron-augmented-colored\",\n",
    "    model = perceptron((512, 512, 3), 0.5),\n",
    "    dataset = config_augmented_colored,\n",
    "    config = {\n",
    "        \"save_weights_only\": True,\n",
    "        \"save_best_only\": True,\n",
    "        \"min_delta\": 0,\n",
    "        \"patience\": 5,\n",
    "        \"epochs\": 20,\n",
    "        \"dropout\": 0.3\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### AlexNet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_models(\n",
    "    name = \"alexNet-augmented-colored\",\n",
    "    model = alex_net((512, 512, 3)),\n",
    "    dataset = config_augmented_colored,\n",
    "    config = {\n",
    "        \"save_weights_only\": True,\n",
    "        \"save_best_only\": True,\n",
    "        \"min_delta\": 0,\n",
    "        \"patience\": 5,\n",
    "        \"epochs\": 20,\n",
    "        \"dropout\": 0.3\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### VGG 16"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_models(\n",
    "    name = \"vgg16-augmented-colored\",\n",
    "    model = vgg_16((512, 512, 3)),\n",
    "    dataset = config_augmented_colored,\n",
    "    config = {\n",
    "        \"save_weights_only\": True,\n",
    "        \"save_best_only\": True,\n",
    "        \"min_delta\": 0,\n",
    "        \"patience\": 5,\n",
    "        \"epochs\": 20,\n",
    "        \"dropout\": 0.3\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### VGG 19"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_models(\n",
    "    name = \"vgg19-augmented-colored\",\n",
    "    model = vgg_19((512, 512, 3)),\n",
    "    dataset = config_augmented_colored,\n",
    "    config = {\n",
    "        \"save_weights_only\": True,\n",
    "        \"save_best_only\": True,\n",
    "        \"min_delta\": 0,\n",
    "        \"patience\": 5,\n",
    "        \"epochs\": 20,\n",
    "        \"dropout\": 0.3\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ResNet 34 - Plain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_models(\n",
    "    name = \"resNet34-augmented-plain-colored\",\n",
    "    model = resnet_34_layers((512, 512, 3), False),\n",
    "    dataset = config_augmented_colored,\n",
    "    config = {\n",
    "        \"save_weights_only\": True,\n",
    "        \"save_best_only\": True,\n",
    "        \"min_delta\": 0,\n",
    "        \"patience\": 5,\n",
    "        \"epochs\": 20,\n",
    "        \"dropout\": 0.3\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ResNet 34 - Residual"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_models(\n",
    "    name = \"resNet34-augmented-residual-colored\",\n",
    "    model = resnet_34_layers((512, 512, 3), True),\n",
    "    dataset = config_augmented_colored,\n",
    "    config = {\n",
    "        \"save_weights_only\": True,\n",
    "        \"save_best_only\": True,\n",
    "        \"min_delta\": 0,\n",
    "        \"patience\": 5,\n",
    "        \"epochs\": 20,\n",
    "        \"dropout\": 0.3\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ResNet 50 - Plain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_models(\n",
    "    name = \"resNet50-augmented-plain-colored\",\n",
    "    model = resnet_50_layers((512, 512, 3), False),\n",
    "    dataset = config_augmented_colored,\n",
    "    config = {\n",
    "        \"save_weights_only\": True,\n",
    "        \"save_best_only\": True,\n",
    "        \"min_delta\": 0,\n",
    "        \"patience\": 5,\n",
    "        \"epochs\": 20,\n",
    "        \"dropout\": 0.3\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ResNet 50 - Residual"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_models(\n",
    "    name = \"resNet50-augmented-residual-colored\",\n",
    "    model = resnet_50_layers((512, 512, 3), True),\n",
    "    dataset = config_augmented_colored,\n",
    "    config = {\n",
    "        \"save_weights_only\": True,\n",
    "        \"save_best_only\": True,\n",
    "        \"min_delta\": 0,\n",
    "        \"patience\": 5,\n",
    "        \"epochs\": 20,\n",
    "        \"dropout\": 0.3\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MobileNet V1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_models(\n",
    "    name = \"mobileNetV1-augmented-colored\",\n",
    "    model = mobilenet_v1((512, 512, 3)),\n",
    "    dataset = config_augmented_colored,\n",
    "    config = {\n",
    "        \"save_weights_only\": True,\n",
    "        \"save_best_only\": True,\n",
    "        \"min_delta\": 0,\n",
    "        \"patience\": 5,\n",
    "        \"epochs\": 20,\n",
    "        \"dropout\": 0.3\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MobileNet V2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "auto_models(\n",
    "    name = \"mobileNetV2-augmented-colored\",\n",
    "    model = mobilenet_v2((512, 512, 3)),\n",
    "    dataset = config_augmented_colored,\n",
    "    config = {\n",
    "        \"save_weights_only\": True,\n",
    "        \"save_best_only\": True,\n",
    "        \"min_delta\": 0,\n",
    "        \"patience\": 5,\n",
    "        \"epochs\": 20,\n",
    "        \"dropout\": 0.3\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
